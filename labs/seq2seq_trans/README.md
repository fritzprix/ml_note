# Seq2Seq Practice for learning experience

> I implemented simple language model for translation task. the model is composed of GRU based encoder and decoder pretrained with causal language model autoregressive task
