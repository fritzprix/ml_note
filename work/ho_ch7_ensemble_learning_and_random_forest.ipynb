{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Etp2a4JoXm2"
   },
   "source": [
    "# Ensemble Learning Algorithm\n",
    "> More heads better than one\n",
    "* Bagging\n",
    "* Boosting\n",
    "* Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u68Ks_kPl-cH"
   },
   "source": [
    "## Voting Classifier\n",
    "* Ensemble various models which trained on the same dataset and select majority vote\n",
    "* show slightly better performance than one\n",
    "* but no big difference. (it's because models trained on same dataset.)\n",
    "\n",
    "**Classifiers should be independent each other**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9630,
     "status": "ok",
     "timestamp": 1606705721908,
     "user": {
      "displayName": "Dwid Lee",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gixfl5X8lgDFyhhUo5D3QhWvc8tKy0Y82fjakYT7Ys=s64",
      "userId": "12313335363494748854"
     },
     "user_tz": -540
    },
    "id": "5eRcWF-vKNHg",
    "outputId": "c706f32f-850f-4bb9-9935-9229d89512ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LogisticRegression', 0.8566666666666667)\n",
      "('RandomForestClassifier', 0.8936666666666667)\n",
      "('SVC', 0.9086666666666666)\n",
      "('VotingClassifier', 0.9063333333333333)\n",
      "('VotingClassifier', 0.904)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "moon_data = make_moons(n_samples=10000, noise=0.3)\n",
    "input = moon_data[0]\n",
    "labels = moon_data[1]\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3)\n",
    "lg_reg = LogisticRegression()\n",
    "rn_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', lg_reg), ('rf', rn_clf), ('svm', svm_clf)],\n",
    "    voting='hard')\n",
    "\n",
    "better_voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', lg_reg), ('rf', rn_clf), ('svm', SVC(probability=True))],\n",
    "    voting='soft')\n",
    "\n",
    "for train_index, test_index in sss.split(input,labels):\n",
    "    train_X, test_X = input[train_index], input[test_index]\n",
    "    train_Y, test_Y = labels[train_index], labels[test_index]\n",
    "\n",
    "\n",
    "voting_clf.fit(train_X, train_Y)\n",
    "\n",
    "for clf in (lg_reg, rn_clf, svm_clf, voting_clf, better_voting_clf):\n",
    "    clf.fit(train_X, train_Y)\n",
    "    pred = clf.predict(test_X)\n",
    "    print(clf.__class__.__name__, accuracy_score(test_Y, pred))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QntOHUb0sG6L"
   },
   "source": [
    "## Bagging & Pasting\n",
    "> training same multiple training algorithm on different random subset of the training set\n",
    "* Bagging : replacement on each sampling (means same data can exist within training input)\n",
    "* Pasting : no replacement on each sampling (every sample is unique within training input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12058,
     "status": "ok",
     "timestamp": 1606705724341,
     "user": {
      "displayName": "Dwid Lee",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gixfl5X8lgDFyhhUo5D3QhWvc8tKy0Y82fjakYT7Ys=s64",
      "userId": "12313335363494748854"
     },
     "user_tz": -540
    },
    "id": "Vp-SzWYOu3MJ",
    "outputId": "bc576d2a-ac5d-4f82-8451-a744ac0e925b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=500, max_samples=100, bootstrap=True,n_jobs=-1)\n",
    "bag_clf.fit(train_X, train_Y)\n",
    "bag_pred = bag_clf.predict(test_X)\n",
    "print(accuracy_score(bag_pred, test_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FV-22HOwvkji"
   },
   "source": [
    "### Out-of-bag evaluation\n",
    "> bagging, some instance remains unsampled => out-of-bag instances. so they can be used for cross-validation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17677,
     "status": "ok",
     "timestamp": 1606705729964,
     "user": {
      "displayName": "Dwid Lee",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gixfl5X8lgDFyhhUo5D3QhWvc8tKy0Y82fjakYT7Ys=s64",
      "userId": "12313335363494748854"
     },
     "user_tz": -540
    },
    "id": "-c8e9OFnwFnp",
    "outputId": "206bb23e-3ac9-4dcd-cf94-b43d488d7dd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.901\n",
      "0.896\n"
     ]
    }
   ],
   "source": [
    "## cross validation using OOB in bagging\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=500, max_samples=1.0, bootstrap=True,n_jobs=-1, oob_score=True)\n",
    "bag_clf.fit(train_X, train_Y)\n",
    "bag_pred = bag_clf.predict(test_X)\n",
    "print(accuracy_score(bag_pred, test_Y))\n",
    "print(bag_clf.oob_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXy_qy-80Tj0"
   },
   "source": [
    "## Random Forests\n",
    "* ensemble of Decision Trees, trained via the bagging or pasting method \n",
    "### Extra-Trees (Extremely Randomized Trees) \n",
    "* faster learning speed (because use of random threshold for split)\n",
    "### Feature Importance\n",
    "> by investigating how much the tree nodes use the feature to reduce impurity on average "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18743,
     "status": "ok",
     "timestamp": 1606705731033,
     "user": {
      "displayName": "Dwid Lee",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gixfl5X8lgDFyhhUo5D3QhWvc8tKy0Y82fjakYT7Ys=s64",
      "userId": "12313335363494748854"
     },
     "user_tz": -540
    },
    "id": "X4U2b3OP5vU0",
    "outputId": "879a9dcc-a778-4c92-a122-1a208bbbbd33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45617774 0.54382226]\n"
     ]
    }
   ],
   "source": [
    "bag_clf = RandomForestClassifier(n_estimators=100,bootstrap=True, n_jobs=-1)\n",
    "bag_clf.fit(train_X, train_Y)\n",
    "bag_pred = bag_clf.predict(test_X)\n",
    "print(bag_clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X3QnJIBa6HGN"
   },
   "source": [
    "## Boosting (Hypothesis boosting)\n",
    "> train predictors sequentially, each trying to correct its predecessor. \n",
    "* Most Popular\n",
    "  * AdaBoost(Adaptive Boosting)\n",
    "    * Sequentially train multiple model, increasing weight on the instances misclassified.\n",
    "  * Gradient Boosting\n",
    "    * Sequentially train multiple model, fitting model to residual error of prior stage\n",
    "    * early stop technique is useful for finding optimal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1771,
     "status": "ok",
     "timestamp": 1606706208504,
     "user": {
      "displayName": "Dwid Lee",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gixfl5X8lgDFyhhUo5D3QhWvc8tKy0Y82fjakYT7Ys=s64",
      "userId": "12313335363494748854"
     },
     "user_tz": -540
    },
    "id": "I9MO8MWi66SI",
    "outputId": "b2520f8a-0ac1-44c8-d136-fe2ff20972b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.916\n"
     ]
    }
   ],
   "source": [
    "## AdaBoost in scikit learn\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=200, algorithm=\"SAMME.R\", learning_rate=0.5)\n",
    "\n",
    "ada_clf.fit(train_X, train_Y)\n",
    "ada_pred = ada_clf.predict(test_X)\n",
    "print(accuracy_score(test_Y,ada_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1021,
     "status": "ok",
     "timestamp": 1606707810947,
     "user": {
      "displayName": "Dwid Lee",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gixfl5X8lgDFyhhUo5D3QhWvc8tKy0Y82fjakYT7Ys=s64",
      "userId": "12313335363494748854"
     },
     "user_tz": -540
    },
    "id": "MMrDNf76Khv3",
    "outputId": "d0322510-b105-4e68-8600-bb6abcc7f215"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimators :  76 0.9173333333333333\n"
     ]
    }
   ],
   "source": [
    "## Gradient Boost in scikit learn\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(max_depth=2, n_estimators=100, learning_rate=0.1)\n",
    "gb_clf.fit(train_X, train_Y)\n",
    "gb_pred = gb_clf.predict(test_X)\n",
    "accuracy_score(test_Y, gb_pred)\n",
    "\n",
    "best_score = 0\n",
    "best_i = 0;\n",
    "\n",
    "accus = [accuracy_score(test_Y, pred) for pred in gb_clf.staged_predict(test_X)]\n",
    "best_esti = np.argmax(accus)\n",
    "\n",
    "\n",
    "print('best estimators : ', best_esti, accus[best_esti])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mLo6yWZ9QC7_"
   },
   "source": [
    "## Stacking\n",
    "* enhanced version of voting classification\n",
    "* aggregating multiple predictions using ml model instead of trivial functions\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6630,
     "status": "ok",
     "timestamp": 1606717244188,
     "user": {
      "displayName": "Dwid Lee",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gixfl5X8lgDFyhhUo5D3QhWvc8tKy0Y82fjakYT7Ys=s64",
      "userId": "12313335363494748854"
     },
     "user_tz": -540
    },
    "id": "Lp50oyreRMRJ",
    "outputId": "f7997b87-1639-4023-8e4f-49f17d243e08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier [0.97777778 0.98148148 0.95910781 0.97026022 0.98141264]\n",
      "RandomForestClassifier 0.9777777777777777\n",
      "ExtraTreesClassifier [0.98148148 0.98148148 0.9739777  0.97769517 0.98884758]\n",
      "ExtraTreesClassifier 0.9844444444444445\n",
      "SVC [0.98148148 0.97407407 0.98884758 0.98884758 0.99256506]\n",
      "SVC 0.9911111111111112\n",
      "[[1 1 1]\n",
      " [3 3 3]\n",
      " [3 3 3]\n",
      " ...\n",
      " [2 2 2]\n",
      " [3 3 3]\n",
      " [9 9 9]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, ExtraTreesClassifier, StackingClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score\n",
    "from sklearn.svm import NuSVC, SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.25)\n",
    "\n",
    "digits = load_digits()\n",
    "list(digits)\n",
    "\n",
    "data = digits['data']\n",
    "labels = digits['target']\n",
    "for train_index, test_index in sss.split(data, labels):\n",
    "  train_X, test_X = data[train_index], data[test_index]\n",
    "  train_Y, test_Y = labels[train_index], labels[test_index]\n",
    "\n",
    "rn_clf = RandomForestClassifier()\n",
    "xtr_clf = ExtraTreesClassifier()\n",
    "svc_clf = SVC(probability=True)\n",
    "vt_clf = VotingClassifier(estimators=[('rn',rn_clf),('xtr', xtr_clf), ('sv', svc_clf)], voting='soft',n_jobs=-1, flatten_transform=True)\n",
    "stk_clf = StackingClassifier(estimators=[('rn',rn_clf),('xtr', xtr_clf), ('sv', svc_clf)], n_jobs=-1)\n",
    "\n",
    "pred_map = []\n",
    "for clf in (rn_clf, xtr_clf, svc_clf):\n",
    "  print(clf.__class__.__name__, cross_val_score(clf,train_X, train_Y))\n",
    "  clf.fit(train_X, train_Y)\n",
    "  pred = clf.predict(test_X)\n",
    "  print(clf.__class__.__name__, accuracy_score(test_Y, pred))\n",
    "  pred_map.append(np.array(pred))\n",
    "  \n",
    "pred_map = np.column_stack(pred_map)\n",
    "print(pred_map)\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1848,
     "status": "ok",
     "timestamp": 1606717474575,
     "user": {
      "displayName": "Dwid Lee",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gixfl5X8lgDFyhhUo5D3QhWvc8tKy0Y82fjakYT7Ys=s64",
      "userId": "12313335363494748854"
     },
     "user_tz": -540
    },
    "id": "LZywnvsExMrE",
    "outputId": "f6f271f1-00d6-4336-d3f0-b8f1d995e43f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9911111111111112"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "blender = DecisionTreeClassifier(max_depth=10)\n",
    "blender.fit(pred_map, test_Y)\n",
    "pred_val = []\n",
    "for clf in (rn_clf, xtr_clf, svc_clf):\n",
    "  clf.fit(train_X, train_Y)\n",
    "  pred = clf.predict(test_X)\n",
    "  pred_val.append(np.array(pred))\n",
    "\n",
    "pred_val = np.column_stack(pred_val)\n",
    "bl_pred = blender.predict(pred_val)\n",
    "accuracy_score(test_Y, bl_pred)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO5GvPV8z5Gh1U0+tOhzegw",
   "collapsed_sections": [],
   "name": "ho_ch7_ensemble_learning_and_random_forest.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
