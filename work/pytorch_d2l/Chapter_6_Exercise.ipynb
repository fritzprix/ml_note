{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beca8d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from d2l import torch as d2l\n",
    "\n",
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e26b8ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : train_loss 0.0069884165634711585 train_acc 0.37726666666666664 / test_acc 0.5925\n",
      "epoch 1 : train_loss 0.0033265372504790625 train_acc 0.7045833333333333 / test_acc 0.7091\n",
      "epoch 2 : train_loss 0.0028586305359999337 train_acc 0.7447333333333334 / test_acc 0.7387\n",
      "epoch 3 : train_loss 0.002632752828796705 train_acc 0.7653166666666666 / test_acc 0.7412\n",
      "epoch 4 : train_loss 0.0024763814533750217 train_acc 0.77975 / test_acc 0.7287\n",
      "epoch 5 : train_loss 0.0023374227305253347 train_acc 0.7932166666666667 / test_acc 0.7693\n",
      "epoch 6 : train_loss 0.002241135024527709 train_acc 0.8043833333333333 / test_acc 0.7885\n",
      "epoch 7 : train_loss 0.0021593581770857177 train_acc 0.8131166666666667 / test_acc 0.7508\n",
      "epoch 8 : train_loss 0.002075414804617564 train_acc 0.8209 / test_acc 0.7944\n",
      "epoch 9 : train_loss 0.0020050736462076503 train_acc 0.8298333333333333 / test_acc 0.7868\n",
      "epoch 10 : train_loss 0.0019484173640608787 train_acc 0.8330666666666666 / test_acc 0.8068\n",
      "epoch 11 : train_loss 0.001887455274661382 train_acc 0.83945 / test_acc 0.7949\n",
      "epoch 12 : train_loss 0.0018502228702108065 train_acc 0.8440666666666666 / test_acc 0.7945\n",
      "epoch 13 : train_loss 0.001797051903605461 train_acc 0.8462833333333334 / test_acc 0.7924\n",
      "epoch 14 : train_loss 0.0017750552480419477 train_acc 0.8511666666666666 / test_acc 0.8192\n",
      "epoch 15 : train_loss 0.0017474306091666222 train_acc 0.8536 / test_acc 0.7865\n",
      "epoch 16 : train_loss 0.0017007500499486923 train_acc 0.8576 / test_acc 0.8306\n",
      "epoch 17 : train_loss 0.001671321713924408 train_acc 0.8608666666666667 / test_acc 0.8109\n",
      "epoch 18 : train_loss 0.0016565528293450674 train_acc 0.8623833333333333 / test_acc 0.8198\n",
      "epoch 19 : train_loss 0.0016263686498006185 train_acc 0.8646 / test_acc 0.8366\n",
      "epoch 20 : train_loss 0.001601878915230433 train_acc 0.8660666666666667 / test_acc 0.838\n",
      "epoch 21 : train_loss 0.0015823909173409143 train_acc 0.8684 / test_acc 0.8343\n",
      "epoch 22 : train_loss 0.001558384720981121 train_acc 0.8695333333333334 / test_acc 0.8397\n",
      "epoch 23 : train_loss 0.001546503658592701 train_acc 0.8719333333333333 / test_acc 0.831\n",
      "epoch 24 : train_loss 0.0015261394570271175 train_acc 0.8736333333333334 / test_acc 0.8308\n",
      "epoch 25 : train_loss 0.001500758625070254 train_acc 0.87555 / test_acc 0.8426\n",
      "epoch 26 : train_loss 0.0014932591552535694 train_acc 0.8769666666666667 / test_acc 0.8373\n",
      "epoch 27 : train_loss 0.0014771977980931599 train_acc 0.87805 / test_acc 0.8267\n",
      "epoch 28 : train_loss 0.001461463463306427 train_acc 0.8794833333333333 / test_acc 0.8456\n",
      "epoch 29 : train_loss 0.0014509449283281962 train_acc 0.88125 / test_acc 0.8478\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "import torch\n",
    "from d2l import torch as d2l\n",
    "\n",
    "X = torch.rand(size=(1,1,28,28))\n",
    "\n",
    "class MyNet(nn.Sequential):\n",
    "    def __init__(self):\n",
    "        super().__init__(nn.Conv2d(1,6, kernel_size=5, padding=2), nn.ReLU(),  \n",
    "                         nn.AvgPool2d(kernel_size=2, stride=2),                \n",
    "                         nn.Conv2d(6,16, kernel_size=5, padding=2), nn.ReLU(),\n",
    "                         nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "                         nn.Flatten(),\n",
    "                         nn.Linear(784, 256),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Linear(256,96),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Linear(96,10))\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "def accuracy(net, X, y):\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval()\n",
    "    return (net(X).argmax(axis=1) == y).sum()\n",
    "\n",
    "def evaluate_accuracy(net, data_iter, device):\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval()\n",
    "    metric = d2l.Accumulator(2)\n",
    "    for X, y in data_iter:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        metric.add(accuracy(net, X, y), y.numel())\n",
    "    return metric[0] / metric[1]\n",
    "        \n",
    "\n",
    "\n",
    "def train_epoch(net, data_iter, loss, updater, device):\n",
    "    metric = d2l.Accumulator(3)\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.train()\n",
    "        net = net.to(device)\n",
    "        loss.to(device)\n",
    "    for X, y in data_iter:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        updater.zero_grad()\n",
    "        l = loss(net(X), y)\n",
    "        l.backward()\n",
    "        updater.step()\n",
    "        acc = accuracy(net, X, y)\n",
    "        metric.add(l,acc, y.numel())\n",
    "    return metric[0] / metric[2], metric[1] / metric[2] \n",
    "    \n",
    "        \n",
    "\n",
    "config = {\n",
    "    'num_epoch': 30,\n",
    "    'learning_rate': 1e-2\n",
    "}\n",
    "\n",
    "net = MyNet()\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "\n",
    "def train(net, train_iter, test_iter, loss, device):\n",
    "    net.apply(init_weights)\n",
    "    updater = torch.optim.SGD(params=net.parameters() ,lr=config['learning_rate'])\n",
    "    num_epoch = config['num_epoch']\n",
    "    for epoch in range(num_epoch):\n",
    "        train_loss, train_acc = train_epoch(net, train_iter, loss, updater, device)\n",
    "        test_acc = evaluate_accuracy(net, test_iter, device)\n",
    "        print(f'epoch {epoch} : train_loss {train_loss} train_acc {train_acc} / test_acc {test_acc}')\n",
    "        \n",
    "    \n",
    "    \n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "train(net, train_iter, test_iter, loss, torch.device('cuda:0'))\n",
    "    \n",
    "    \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
