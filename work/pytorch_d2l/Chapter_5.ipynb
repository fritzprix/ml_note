{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e02efe6",
   "metadata": {},
   "source": [
    "# Chapter 5. Deep Learning Computation\n",
    "\n",
    "## Layer & Blocks\n",
    "- Single neuron\n",
    "  - 여러개의 입력이 있고\n",
    "  - 하나의 Scalar 출력을 갖고\n",
    "  - Paramter들을 가짐 (w.....,b)\n",
    "- Layer\n",
    "  - has Set of Input\n",
    "  - generate corresponding output\n",
    "  - parameter들을 가짐 \n",
    "- Model \n",
    "  - Layer와 동일한 특징을 가짐 (Set of Input / Corresponding Output / Tunaable Paramter)\n",
    "> MLP의 경우 Model과 Layer는 이처럼 공통적인 특징 그리고 구조를 가지고 있음\n",
    "\n",
    "- block\n",
    "  - 단일 layer 혹은 group of layer 혹은 전체 Model 일수 있음\n",
    "  - 여러개의 block을 조합하여 더 복잡한 모델을 만들 수 있음\n",
    "  - 프로그램 관점에서 보면 class 임\n",
    "  \n",
    " \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9181ef62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1549,  0.0502,  0.0058,  0.0386,  0.0868,  0.0649, -0.0149, -0.0220,\n",
       "         -0.0678,  0.0866],\n",
       "        [ 0.1514,  0.0507,  0.0057,  0.0409,  0.0848,  0.0598, -0.0138, -0.0212,\n",
       "         -0.0703,  0.0874]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out = nn.Linear(256, 10)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.out(self.relu(self.hidden(X)))\n",
    "    \n",
    "X = torch.normal(0, std=0.01, size=(2, 20), dtype=torch.float32)\n",
    "\n",
    "net = MLP()\n",
    "net(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91fead2",
   "metadata": {},
   "source": [
    "- nn.Module class는 _modules 속성을 지니고 있으며 framework은 parameter 초기화 시 이 _modules 속성을 검사하여 재귀적으로 paramter 초기화를 수행한다.  \n",
    "  - nn.Module\n",
    "    - _modulues\n",
    "      - nn.Module\n",
    "        - _modules ....\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "58233cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2x4 and 20x256)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_63/2363863011.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMySequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_63/2363863011.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'block'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2x4 and 20x256)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MySequential(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        for idx, module in enumerate(args):\n",
    "            self._modules[str(idx)] = module\n",
    "    \n",
    "    def forward(self, X):\n",
    "        for block in self._modules.values():\n",
    "            X = block(X)\n",
    "        return X\n",
    "\n",
    "net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256,10))\n",
    "net(X)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc9b3c5",
   "metadata": {},
   "source": [
    "## Parameter Management\n",
    "- 모델로 부터 parameter를 추출하고 이를 이용하여 진단, 시각화 하기\n",
    "- paramter 초기화\n",
    "- 서로 다른 모델 요소간의 parameter 교환\n",
    "\n",
    "### Accessing Parameter from Model - state_dict()\n",
    "- weight과 bias의 정보를 포함\n",
    "- float32 형식\n",
    "- index를 이용하여 특정 layer를 지정할 수 있음\n",
    "- Parameter class의 instance\n",
    "- grad 속성을 가지고 있음. 하지만 backward를 하지 않았기 때문에 None 임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "406c4f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('weight', tensor([[-0.0106, -0.0027,  0.1652, -0.0301,  0.2782,  0.2915,  0.3414, -0.1533]])), ('bias', tensor([-0.0782]))])\n",
      "Parameter containing:\n",
      "tensor([[-0.0106, -0.0027,  0.1652, -0.0301,  0.2782,  0.2915,  0.3414, -0.1533]],\n",
      "       requires_grad=True)\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "tensor([[-0.0106, -0.0027,  0.1652, -0.0301,  0.2782,  0.2915,  0.3414, -0.1533]])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "net = nn.Sequential(nn.Linear(4,8), nn.ReLU(), nn.Linear(8,1))\n",
    "X = torch.normal(0, std=0.1, size=(2,4))\n",
    "net(X)\n",
    "\n",
    "print(net[2].state_dict())\n",
    "print(net[2].weight)\n",
    "print(type(net[2].weight))\n",
    "print(net[2].weight.data)\n",
    "print(net[2].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8bff8618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('weight', <built-in method size of Parameter object at 0x7f2bb3a15310>) ('bias', <built-in method size of Parameter object at 0x7f2bb3a152c0>)\n"
     ]
    }
   ],
   "source": [
    "print(*[(name, param.size) for name, param in net[0].named_parameters()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec379b5c",
   "metadata": {},
   "source": [
    "### Access Parameters from Nested Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c62acc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2039],\n",
      "        [0.2039]], grad_fn=<AddmmBackward0>)\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n",
      "tensor([[-0.2618, -0.1816, -0.2423,  0.2877],\n",
      "        [-0.0848, -0.2049,  0.3262, -0.1435],\n",
      "        [ 0.0769,  0.0082,  0.2581, -0.0372],\n",
      "        [ 0.4861,  0.2899,  0.0511,  0.4639],\n",
      "        [ 0.4631,  0.3644, -0.2023, -0.3040],\n",
      "        [ 0.2696,  0.3049,  0.2168, -0.3931],\n",
      "        [-0.2882,  0.4209,  0.4515, -0.1698],\n",
      "        [-0.1399, -0.4974, -0.1007,  0.3721]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def model1():\n",
    "    return nn.Sequential(nn.Linear(4,8), nn.ReLU(), \n",
    "                         nn.Linear(8,4), nn.ReLU())\n",
    "\n",
    "def model2():\n",
    "    net = nn.Sequential()\n",
    "    for i in range(5):\n",
    "        net.add_module(f'{i}',model1())\n",
    "    return net\n",
    "\n",
    "rgnet = nn.Sequential(model2(), nn.Linear(4,1))\n",
    "print(rgnet(X))\n",
    "print(rgnet)\n",
    "print(rgnet[0][0][0].weight.data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25942f0e",
   "metadata": {},
   "source": [
    "### Paramter Initialization\n",
    "#### Built-in Initialization\n",
    "- zero / normal / const ... 다앙햔 pre-defined initializer가 제공됨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b5cbd091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1.]) tensor(0.)\n",
      "tensor([[-1.8210e-01,  1.7192e-01,  2.7038e-01, -9.0876e-01],\n",
      "        [-3.6169e-01,  5.4119e-01, -3.3802e-01, -6.8608e-01],\n",
      "        [ 2.4508e-01, -1.3278e-01, -1.3855e-01, -7.7812e-04],\n",
      "        [ 3.6397e-03, -3.9097e-01, -2.2136e-01, -2.9122e-01],\n",
      "        [-7.2229e-01,  3.1027e-01,  1.7012e-02,  3.7291e-01],\n",
      "        [-6.6274e-01, -5.8979e-01, -3.3946e-01, -2.6099e-01],\n",
      "        [-9.0365e-03, -9.6022e-02, -6.1467e-01, -4.1452e-01],\n",
      "        [-1.8167e-01, -3.8665e-01, -4.8293e-01, -4.8055e-01]])\n",
      "tensor([[10.4461, 10.4819, 10.8835, 10.9754, 10.4175, 10.1001, 10.9889, 10.8458]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def init_normal(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight,std=0.01)\n",
    "        nn.init.zeros_(m.bias)\n",
    "\n",
    "def init_const(m):   \n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.constant_(m.weight,1) \n",
    "        nn.init.zeros_(m.bias)\n",
    "\n",
    "def init_xavier(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "def init_custom(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        m.weight.data = torch.rand(size=m.weight.data.shape)\n",
    "        m.weight.data += 10\n",
    "        \n",
    "net.apply(init_const)\n",
    "print(*[net[0].weight.data[0], net[0].bias.data[0]])\n",
    "\n",
    "net[0].apply(init_xavier)\n",
    "net[2].apply(init_custom)\n",
    "print(net[0].weight.data)\n",
    "print(net[2].weight.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f094bc3",
   "metadata": {},
   "source": [
    "#### Tied Parameters \n",
    "- 서로 다른 Layer들 간에 paramter를 공유하도록 할 수 있음 \n",
    "- paramter가 공유된다기 보다는 실제로는 하나의 Layer를 여러 layer에서 참조하는 느낌\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f7cc3696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True, True, True, True])\n",
      "tensor([True, True, True, True, True, True, True, True])\n",
      "tensor([ 1.0000e+02, -2.7184e-02, -2.6191e-01, -1.8853e-01, -1.5053e-01,\n",
      "         1.8554e-01, -2.5032e-01, -3.1696e-01])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "shared = nn.Linear(8,8)\n",
    "\n",
    "net = nn.Sequential(nn.Linear(4,8), nn.ReLU(),\n",
    "                   shared, nn.ReLU(),\n",
    "                   shared, nn.ReLU(),\n",
    "                   nn.Linear(8,1))\n",
    "\n",
    "net(X)\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0]) # 1. value of parameters should be same \n",
    "net[2].weight.data[0][0] = 100                        # 2. modification of paramters of shared \n",
    "                                                      # paramter is visible from the others\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0]) \n",
    "print(net[2].weight.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3603c412",
   "metadata": {},
   "source": [
    "## Custom Layers\n",
    "### Layers without parameters\n",
    "- parameter가 없는 임의의 layer를 nn.Module을 상속하여 만들 수 있음 \n",
    "- 이렇게 만들어진 custom layers는 다른 layer들과 함께 block처럼 modular하게 사용될 수 있음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d9fe9264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.3132e-09, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class CenteredLayer(nn.Module):  # element wise mean 값을 빼주는 custom layer\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return X - X.mean()\n",
    "    \n",
    "    \n",
    "layer = CenteredLayer()\n",
    "\n",
    "net = nn.Sequential(nn.Linear(4, 8), CenteredLayer())\n",
    "\n",
    "Y = net(X)   \n",
    "Y.mean()   # 결과물의 mean이 0 인지(매우 가까운지 확인)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba09f89b",
   "metadata": {},
   "source": [
    "### Layers with Parameters (Linear Layer Internal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ddf2d27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4483, 0.1872, 0.9252, 0.2744, 0.6789, 0.8821, 0.5642, 0.8725],\n",
      "        [0.6620, 0.9309, 0.1771, 0.3165, 0.0416, 0.7485, 0.8869, 0.7954],\n",
      "        [0.7602, 0.9064, 0.8001, 0.6923, 0.8938, 0.5408, 0.8832, 0.1485],\n",
      "        [0.9549, 0.1790, 0.8704, 0.5390, 0.7758, 0.2422, 0.7196, 0.1501]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, in_count, out_count):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.rand(size=(in_count, out_count), dtype=torch.float32))\n",
    "        self.bias = nn.Parameter(torch.tensor(0, dtype=torch.float32))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return torch.matmul(X, self.weight) + self.bias\n",
    "\n",
    "net = nn.Sequential(MyLinear(4,8), nn.ReLU())\n",
    "net(X)\n",
    "print(net[0].weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8578142b",
   "metadata": {},
   "source": [
    "## File I/O\n",
    "- 학습된 모델의 저장 및 불러오기\n",
    "- 아주 오랜 기간 동안의 training을 진행할 경우 주기적으로 모델을 저장하는 것이 최선\n",
    "\n",
    "### Loading and Saving Tensors\n",
    "- tensors들을 저장할 때 torch에서 제공되는 ```save()``` 그리고 ```load()``` 함수를 사용\n",
    "- 저장 시 이름을 아래와 같이 지정하여 복원시에 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8e17dd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7295, 0.3096, 0.3754, 0.5856],\n",
      "        [0.0182, 0.3196, 0.7680, 0.8578]])\n",
      "tensor([[0.7295, 0.3096, 0.3754, 0.5856],\n",
      "        [0.0182, 0.3196, 0.7680, 0.8578]])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "xx = torch.rand(size=(2,4))\n",
    "torch.save(xx, 'file-x')\n",
    "print(xx)\n",
    "xxx = torch.load('file-x')\n",
    "print(xxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f495b98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.3573, 0.2071],\n",
       "        [0.0000, 0.0000, 0.3579, 0.2082]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        for i in range(5):\n",
    "            self._modules[str(i)] = nn.Sequential(nn.Linear(4,4), nn.ReLU())\n",
    "        \n",
    "    def forward(self, X):\n",
    "        for model in self._modules.values():\n",
    "            X = model(X)\n",
    "        return X\n",
    "\n",
    "net = MLP()\n",
    "torch.save(net, 'model')  # save model as a whole\n",
    "\n",
    "net2 = torch.load('model') # load model \n",
    "net2(X)\n",
    "\n",
    "\n",
    "torch.save(net.state_dict(), 'model_param')  # save only parameters of the model\n",
    "\n",
    "clone = MLP()\n",
    "clone.load_state_dict(torch.load('model_param')) # load saved parameters into empty model\n",
    "\n",
    "clone(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be11ba0a",
   "metadata": {},
   "source": [
    "### Saving Whole Model vs. Saving model paramters using ```state_dict()```\n",
    "- ```torch.save()```를 이용하여 model을 저장하면 pickle 직렬화를 이용하게되는데, 이때 class에 대한 정의가 필요하며 해당 class 정의에 대한 참조 (directory path)를 저장한다. 따라서 다른 환경에서 모델을 불러 올경우 이러한 경로의 차이에 의해서 깨질 수 있다.\n",
    "- ```state_dict()```를 사용하는 것이 권장됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4987790d",
   "metadata": {},
   "source": [
    "## GPU\n",
    "### Computing Devices\n",
    "- ```torch.device()```를 이용하여 저장 및 연산 장치를 선택할 수 있다. \n",
    "- Default로 CPU로 지정된다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "76614a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr 17 13:22:59 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\n",
      "| 30%   33C    P8    16W / 130W |    364MiB /  2048MiB |     30%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1867      G                                      50MiB |\n",
      "|    0   N/A  N/A      4928      G                                     123MiB |\n",
      "|    0   N/A  N/A      5132      G                                      28MiB |\n",
      "|    0   N/A  N/A      5957      G                                     147MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "cuda cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "!nvidia-smi\n",
    "print(*[torch.device('cuda'), torch.device('cpu')])\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "183f7d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[device(type='cuda', index=0)]\n"
     ]
    }
   ],
   "source": [
    "def try_gpu(i=0):\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "def try_all_gpus():\n",
    "    devices = [torch.device(f'cuda:{i}') for i in range(torch.cuda.device_count())]\n",
    "    return devices if devices else [torch.device('cpu')]\n",
    "\n",
    "devices = try_all_gpus()\n",
    "print(devices)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf93c5e7",
   "metadata": {},
   "source": [
    "### Tensors and GPUs\n",
    "- Default로 모든 tensor는 CPU의 memory에 생성된다.\n",
    "- tensor가 생성 될 device를 지정할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6efae43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.3574, 0.2090],\n",
       "        [0.0000, 0.0000, 0.3574, 0.2099],\n",
       "        [0.0000, 0.0000, 0.3574, 0.2109],\n",
       "        [0.0000, 0.0000, 0.3574, 0.2092]], device='cuda:0',\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "yy = torch.tensor([2,4], dtype=torch.float32)\n",
    "print(yy.device) # tensor created @ CPU\n",
    "\n",
    "xx = torch.tensor([2,4], dtype=torch.float32, device=try_gpu())\n",
    "print(xx.device) # tensor created @ GPU if you have one\n",
    "\n",
    "xx\n",
    "\n",
    "yy.cuda(0) is yy\n",
    "\n",
    "net.to(try_gpu())\n",
    "net(torch.rand(size=(4,4), device=try_gpu()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
